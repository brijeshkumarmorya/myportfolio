<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Fake News Detection Using TF-IDF and Machine Learning | Brijesh Kumar Morya</title>
  <meta name="description" content="How I trained a Gradient Boosting ensemble on 44K news articles using TF-IDF feature extraction to achieve 99.48% accuracy with sub-second CPU inference. By Brijesh Kumar Morya, B.Tech CSE student at University of Delhi.">
  <meta name="author" content="Brijesh Kumar Morya">
  <meta name="robots" content="index, follow">
  <link rel="canonical" href="https://brijeshkumarmorya.in/blog/fake-news-detection-tfidf-machine-learning.html">
  <meta property="og:title" content="Fake News Detection Using TF-IDF and Machine Learning | Brijesh Kumar Morya">
  <meta property="og:type" content="article">
  <script type="application/ld+json">
  {"@context":"https://schema.org","@type":"Article","headline":"Fake News Detection Using TF-IDF and Machine Learning","author":{"@type":"Person","name":"Brijesh Kumar Morya","url":"https://brijeshkumarmorya.in/"},"url":"https://brijeshkumarmorya.in/blog/fake-news-detection-tfidf-machine-learning.html","keywords":["TF-IDF fake news detection","machine learning text classification","gradient boosting sklearn","fake news NLP Python","scikit-learn classification","ML project India","University of Delhi CSE machine learning"],"breadcrumb":{"@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Home","item":"https://brijeshkumarmorya.in/"},{"@type":"ListItem","position":2,"name":"Blog","item":"https://brijeshkumarmorya.in/blog/"},{"@type":"ListItem","position":3,"name":"Fake News Detection","item":"https://brijeshkumarmorya.in/blog/fake-news-detection-tfidf-machine-learning.html"}]}}
  </script>
  <link rel="preconnect" href="https://fonts.googleapis.com"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Syne:wght@400;600;700;800&family=DM+Sans:ital,opsz,wght@0,9..40,300;0,9..40,400;0,9..40,500;1,9..40,300&family=JetBrains+Mono:wght@300;400;500&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
  <style>:root{--bg:#080f1c;--surface:#0c1526;--border:rgba(0,245,212,.08);--border-mid:rgba(0,245,212,.18);--text-head:#e8f4ff;--text-body:#7e92b5;--text-muted:#4a5f80;--text-label:#a0b4cf;--accent:#00F5D4;--accent-dim:rgba(0,245,212,.12);--font-head:'Syne',sans-serif;--font-body:'DM Sans',sans-serif;--font-mono:'JetBrains Mono',monospace}*,*::before,*::after{box-sizing:border-box;margin:0;padding:0}body{font-family:var(--font-body);background:var(--bg);color:var(--text-body);line-height:1.7;overflow-x:hidden;-webkit-font-smoothing:antialiased}a{color:var(--accent);text-decoration:none}a:hover{text-decoration:underline}.navbar{position:fixed;top:0;left:0;right:0;z-index:100;padding:.9rem 0;background:rgba(8,15,28,.9);backdrop-filter:blur(20px);border-bottom:1px solid var(--border)}.nav-inner{max-width:760px;margin:0 auto;padding:0 1.5rem;display:flex;align-items:center;justify-content:space-between}.nav-logo{font-family:var(--font-head);font-size:1.2rem;font-weight:800;color:var(--accent)}.nav-back{font-family:var(--font-mono);font-size:.82rem;color:var(--text-label);display:flex;align-items:center;gap:.5rem}.nav-back:hover{color:var(--accent);text-decoration:none}.article-wrap{max-width:760px;margin:0 auto;padding:7rem 1.5rem 5rem}.breadcrumbs{font-family:var(--font-mono);font-size:.75rem;color:var(--text-muted);margin-bottom:2rem;display:flex;gap:.5rem;align-items:center;flex-wrap:wrap}.breadcrumbs a{color:var(--text-muted)}.breadcrumbs a:hover{color:var(--accent)}.breadcrumbs span{color:var(--accent)}.article-tags{display:flex;flex-wrap:wrap;gap:.4rem;margin-bottom:1.5rem}.article-tag{font-family:var(--font-mono);font-size:.72rem;color:var(--accent);background:var(--accent-dim);border:1px solid var(--border-mid);border-radius:100px;padding:.2rem .8rem}h1.article-title{font-family:var(--font-head);font-size:clamp(1.8rem,4vw,2.8rem);font-weight:800;color:var(--text-head);line-height:1.15;letter-spacing:-.03em;margin-bottom:1.5rem}.article-meta{font-family:var(--font-mono);font-size:.8rem;color:var(--text-muted);margin-bottom:2.5rem;padding-bottom:2rem;border-bottom:1px solid var(--border);display:flex;gap:1.5rem;flex-wrap:wrap}.article-meta span{display:flex;align-items:center;gap:.4rem}.article-meta i{color:var(--accent)}.article-body h2{font-family:var(--font-head);font-size:1.6rem;font-weight:700;color:var(--text-head);margin:2.5rem 0 1rem;letter-spacing:-.02em}.article-body h3{font-family:var(--font-head);font-size:1.2rem;font-weight:600;color:var(--text-label);margin:2rem 0 .75rem}.article-body p{font-size:1rem;line-height:1.85;color:var(--text-body);margin-bottom:1.25rem}.article-body strong{color:var(--text-label);font-weight:500}.article-body ul,.article-body ol{margin:1rem 0 1.5rem 1.5rem;display:flex;flex-direction:column;gap:.5rem}.article-body li{font-size:.97rem;color:var(--text-body);line-height:1.75}.article-body pre{background:var(--surface);border:1px solid var(--border-mid);border-radius:8px;padding:1.25rem 1.5rem;overflow-x:auto;margin:1.5rem 0;font-family:var(--font-mono);font-size:.83rem;line-height:1.6;color:#a0c4ff}.article-body code{font-family:var(--font-mono);font-size:.88em;color:var(--accent);background:var(--accent-dim);padding:.1rem .4rem;border-radius:3px}.article-body pre code{color:#a0c4ff;background:none;padding:0;font-size:1em}.stat-grid{display:grid;grid-template-columns:repeat(auto-fit,minmax(140px,1fr));gap:1rem;margin:1.5rem 0}.stat-box{background:var(--surface);border:1px solid var(--border-mid);border-radius:8px;padding:1rem;text-align:center}.stat-val{font-family:var(--font-head);font-size:1.6rem;font-weight:800;color:var(--accent)}.stat-lbl{font-family:var(--font-mono);font-size:.72rem;color:var(--text-muted);margin-top:.25rem}.article-footer{margin-top:4rem;padding-top:2rem;border-top:1px solid var(--border)}.author-card{display:flex;gap:1rem;align-items:flex-start;background:var(--surface);border:1px solid var(--border);border-radius:12px;padding:1.5rem}.author-avatar{width:60px;height:60px;border-radius:50%;background:var(--accent-dim);border:2px solid var(--border-mid);display:flex;align-items:center;justify-content:center;flex-shrink:0;font-family:var(--font-head);font-weight:800;color:var(--accent);font-size:1.2rem}.author-name{font-family:var(--font-head);font-weight:700;color:var(--text-head);margin-bottom:.25rem}.author-bio{font-size:.9rem;color:var(--text-body);line-height:1.65}.related-posts{margin-top:3rem}.related-posts h3{font-family:var(--font-head);font-size:1.2rem;font-weight:700;color:var(--text-head);margin-bottom:1rem}.related-list{display:flex;flex-direction:column;gap:.75rem}.related-item{display:flex;align-items:center;gap:.75rem;padding:.75rem 1rem;background:var(--surface);border:1px solid var(--border);border-radius:8px;transition:border-color .2s}.related-item:hover{border-color:var(--border-mid);text-decoration:none}.related-item i{color:var(--accent);flex-shrink:0}.related-item span{font-size:.9rem;color:var(--text-label)}footer{margin-top:4rem;border-top:1px solid var(--border);padding:1.5rem;text-align:center;font-family:var(--font-mono);font-size:.75rem;color:var(--text-muted)}footer a{color:var(--accent)}</style>
</head>
<body>
  <nav class="navbar">
    <div class="nav-inner">
      <a href="/" class="nav-logo">[BKM]</a>
      <a href="/blog/" class="nav-back"><i class="fas fa-arrow-left"></i> All Articles</a>
    </div>
  </nav>

  <article class="article-wrap" itemscope itemtype="https://schema.org/Article">
    <nav class="breadcrumbs" aria-label="Breadcrumb">
      <a href="/">Home</a><span>/</span><a href="/blog/">Blog</a><span>/</span><span>Fake News Detection</span>
    </nav>
    <div class="article-tags">
      <span class="article-tag">Machine Learning</span><span class="article-tag">Python</span>
      <span class="article-tag">TF-IDF</span><span class="article-tag">Scikit-learn</span>
    </div>
    <h1 class="article-title" itemprop="headline">Fake News Detection Using TF-IDF and Machine Learning</h1>
    <div class="article-meta">
      <span><i class="fas fa-user"></i> Brijesh Kumar Morya</span>
      <span><i class="fas fa-clock"></i> 6 min read</span>
      <span><i class="fas fa-tag"></i> Machine Learning</span>
    </div>

    <div class="article-body" itemprop="articleBody">
      <p>
        Misinformation spreads faster than corrections. My <strong>Fake News Detector</strong> project tackled this as an NLP classification problem: given the text of a news article, predict whether it is real or fake. In this article I walk through the complete pipeline — data preparation, TF-IDF feature extraction, model selection, ensemble construction, and hyperparameter optimisation — that produced <strong>99.48% accuracy</strong> on a held-out test set.
      </p>

      <div class="stat-grid">
        <div class="stat-box"><div class="stat-val">99.48%</div><div class="stat-lbl">Test Accuracy</div></div>
        <div class="stat-box"><div class="stat-val">44K</div><div class="stat-lbl">Articles</div></div>
        <div class="stat-box"><div class="stat-val">80K</div><div class="stat-lbl">Vocab Size</div></div>
        <div class="stat-box"><div class="stat-val">&lt;1s</div><div class="stat-lbl">CPU Inference</div></div>
      </div>

      <h2>The Dataset</h2>
      <p>
        I combined two publicly available datasets: <strong>ISOT Fake News Dataset</strong> and the <strong>Kaggle Fake News</strong> corpus, producing 44,898 articles — roughly 50/50 real/fake. This balanced split is important: an unbalanced dataset can yield artificially high accuracy while completely failing on the minority class.
      </p>
      <pre><code>import pandas as pd

real = pd.read_csv('True.csv')
fake = pd.read_csv('Fake.csv')

real['label'] = 1
fake['label'] = 0

df = pd.concat([real, fake]).sample(frac=1, random_state=42).reset_index(drop=True)
df['text'] = df['title'] + ' ' + df['text']   # Combine title + body

print(df['label'].value_counts())
# 1    23481
# 0    21417</code></pre>

      <h2>Text Preprocessing</h2>
      <p>
        Raw news text is noisy. I applied a lightweight cleaning pipeline before feature extraction:
      </p>
      <pre><code>import re

def clean_text(text):
    text = text.lower()
    text = re.sub(r'https?://\S+', '', text)       # Remove URLs
    text = re.sub(r'\[.*?\]', '', text)             # Remove bracketed text
    text = re.sub(r'[^a-z\s]', '', text)           # Keep letters only
    text = re.sub(r'\s+', ' ', text).strip()
    return text

df['text'] = df['text'].apply(clean_text)</code></pre>
      <p>
        I deliberately <strong>did not</strong> apply stemming or stop-word removal. With a large enough TF-IDF vocabulary (80K features), the model learns which stop words are discriminative for fake news style (e.g., excessive use of "breaking", "shocking").
      </p>

      <h2>TF-IDF Feature Extraction</h2>
      <p>
        <strong>Term Frequency–Inverse Document Frequency (TF-IDF)</strong> represents each article as a sparse vector of weighted word frequencies. Words that appear frequently in one article but rarely across the corpus get high weight — they are the most discriminative features.
      </p>
      <pre><code>from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    df['text'], df['label'], test_size=0.2, random_state=42, stratify=df['label']
)

vectorizer = TfidfVectorizer(
    max_features=80_000,
    ngram_range=(1, 2),      # Unigrams + bigrams
    sublinear_tf=True,       # Log-scale TF — reduces impact of very frequent terms
    min_df=2,                # Ignore terms appearing in only 1 document
)

X_train_tfidf = vectorizer.fit_transform(X_train)
X_test_tfidf  = vectorizer.transform(X_test)</code></pre>
      <p>
        Using <code>ngram_range=(1,2)</code> captures phrases like "breaking news" and "fake president" as single features — these bigrams are highly predictive of fake news.
      </p>

      <h2>Model Selection and Ensemble</h2>
      <p>
        I trained and evaluated three classifiers individually, then combined them via soft-voting:
      </p>
      <pre><code>from sklearn.ensemble import GradientBoostingClassifier, VotingClassifier, RandomForestClassifier
from sklearn.linear_model import LogisticRegression

gb  = GradientBoostingClassifier(n_estimators=200, max_depth=5, random_state=42)
rf  = RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=42)
lr  = LogisticRegression(C=1.0, max_iter=1000, solver='lbfgs')

ensemble = VotingClassifier(
    estimators=[('gb', gb), ('rf', rf), ('lr', lr)],
    voting='soft'   # Average predicted probabilities — better than hard majority vote
)

ensemble.fit(X_train_tfidf, y_train)</code></pre>

      <h3>Individual Model Accuracy (before ensemble)</h3>
      <ul>
        <li>Logistic Regression: 98.67%</li>
        <li>Random Forest: 98.91%</li>
        <li>Gradient Boosting: 99.12%</li>
        <li><strong>Soft Voting Ensemble: 99.48%</strong></li>
      </ul>
      <p>
        The ensemble outperforms any single model because the three learners make <strong>different errors</strong>. Combining them via soft voting averages out individual mistakes.
      </p>

      <h2>Hyperparameter Optimisation</h2>
      <p>
        I used <code>GridSearchCV</code> with 5-fold stratified cross-validation to tune the Gradient Boosting model:
      </p>
      <pre><code>from sklearn.model_selection import GridSearchCV

param_grid = {
    'n_estimators': [100, 200],
    'max_depth': [3, 5],
    'learning_rate': [0.05, 0.1],
    'subsample': [0.8, 1.0]
}

gs = GridSearchCV(
    GradientBoostingClassifier(random_state=42),
    param_grid,
    cv=5,
    scoring='accuracy',
    n_jobs=-1
)
gs.fit(X_train_tfidf, y_train)
print(gs.best_params_)
# {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200, 'subsample': 0.8}</code></pre>

      <h2>Model Evaluation</h2>
      <pre><code>from sklearn.metrics import classification_report, confusion_matrix

y_pred = ensemble.predict(X_test_tfidf)
print(classification_report(y_test, y_pred))
#               precision    recall  f1-score
# 0 (Fake)       0.994       0.996     0.995
# 1 (Real)       0.996       0.994     0.995
# accuracy                             0.9948</code></pre>
      <p>
        Both precision and recall exceed 99% for each class — confirming the model is not over-fitting to one class. The confusion matrix shows only 47 misclassifications across 8,980 test articles.
      </p>

      <h2>Key Lessons for ML Engineers</h2>
      <ul>
        <li><strong>Feature engineering matters more than model choice</strong> at this scale. The jump from a basic unigram TF-IDF to a bigram TF-IDF with <code>sublinear_tf</code> added 0.6% accuracy.</li>
        <li><strong>Ensembles are almost always worth it</strong> when you have multiple uncorrelated learners.</li>
        <li><strong>Always stratify your train/test split</strong> on the label column to ensure balanced representation.</li>
        <li><strong>Classical ML still wins</strong> over neural networks for tabular/structured text problems when training data is limited and inference speed matters.</li>
      </ul>

      <h2>Conclusion</h2>
      <p>
        A well-engineered classical ML pipeline — TF-IDF features, a Gradient Boosting ensemble, and careful cross-validation — can achieve near-perfect accuracy on news classification without any neural networks or GPU compute. The full code is available on <a href="https://github.com/brijeshkumarmorya/Fake-News-Detection-Tool" target="_blank" rel="noopener noreferrer">GitHub</a>.
      </p>
    </div>

    <footer class="article-footer">
      <div class="author-card">
        <div class="author-avatar">BK</div>
        <div>
          <div class="author-name">Brijesh Kumar Morya</div>
          <div class="author-bio">Backend-focused Full-Stack Developer and ML practitioner. B.Tech CSE @ University of Delhi. Open to backend engineering internships in Delhi and remotely.</div>
        </div>
      </div>
      <div class="related-posts">
        <h3>Continue Reading</h3>
        <div class="related-list">
          <a href="expense-splitting-app-nodejs-mongodb.html" class="related-item"><i class="fas fa-arrow-right"></i><span>How I Built a Real-Time Expense Splitting App with Node.js & MongoDB</span></a>
          <a href="designing-scalable-rest-apis-btech.html" class="related-item"><i class="fas fa-arrow-right"></i><span>Designing Scalable REST APIs as a B.Tech CSE Student</span></a>
          <a href="backend-systems-clean-architecture.html" class="related-item"><i class="fas fa-arrow-right"></i><span>Building Backend Systems with Clean Architecture in Node.js</span></a>
        </div>
      </div>
    </footer>
  </article>
  <footer><a href="/">brijeshkumarmorya.in</a> · Backend Developer · B.Tech CSE, University of Delhi</footer>
</body>
</html>
